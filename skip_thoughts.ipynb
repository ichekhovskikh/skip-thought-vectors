{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skip-thoughts",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/ichekhovskikh/skip-thought-vectors/blob/master/skip_thoughts.ipynb",
      "authorship_tag": "ABX9TyMqT1UdQArFTjtvHjWo8emZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ichekhovskikh/skip-thought-vectors/blob/master/skip_thoughts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNlBN9L9--GG",
        "colab_type": "text"
      },
      "source": [
        "# Подготовка\n",
        "\n",
        "Установим флаг floatX=float32, чтобы избежать ошибок типа TypeError."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qauJ0E_8-sb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo -e \"\\n[global]\\nfloatX=float32\\n\" >> ~/.theanorc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_eIsNhu_xKu",
        "colab_type": "text"
      },
      "source": [
        "Необходимо подлючить Google Drive, где по пути skip-thoughts-master/training располагается библиотека для работы со Skip Throughts Vectors. Папку training можно скачать из репозитория https://github.com/ichekhovskikh/skip-thought-vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyz9TC-oQgu2",
        "colab_type": "code",
        "outputId": "310725ba-5ac7-47cf-e78b-a9a968cc4826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXJz0dqR_2Xd",
        "colab_type": "text"
      },
      "source": [
        "Сделать импорт библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WetwZIyMQdzp",
        "colab_type": "code",
        "outputId": "b8c3bb8a-bd9b-4ab9-d0fe-1c6366f360e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import importlib.util\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/skip-thoughts-master/training')\n",
        "import vocab\n",
        "import train\n",
        "import tools"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGRN0p7pAMbW",
        "colab_type": "code",
        "outputId": "13eaf085-a7b1-4402-f029-67003545b012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install pymorphy2[fast]\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import os\n",
        "import collections\n",
        "import smart_open\n",
        "import random\n",
        "import json\n",
        "import urllib.request\n",
        "import pymorphy2\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymystem3 import Mystem"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.3MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 53.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=862191 sha256=aeebc0b1daa773b3ec116a29fb2e6c80743a256b9c8f808bd71688741b15f363\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZYD5AXcNYRU",
        "colab_type": "text"
      },
      "source": [
        "#Начинаем\n",
        "Для начала нам понадобится комплект документов для обучения нашей модели doc2vec. Теоретически, документ может быть чем угодно: коротким твитом из 140 символов, отдельным абзацем, новостной статьей или книгой. В NLP комплект документов часто называют корпусом.\n",
        "\n",
        "Будем тренировать нашу модель на собственном корпусе. Этот корпус содержит 70 текстов.\n",
        "\n",
        "И мы проверим нашу модель на глаз, используя тестовый корпус, который содержит 7 документов.\n",
        "\n",
        "Dataset состоит из трех строк: id (идентификатор строки), text (текст статьи), tag (идентификатор самой статьи, вектор которого будем обучать)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KR5mKmSVAc-L",
        "colab": {}
      },
      "source": [
        "#@title Введите путь к файлам исходной базы статей:\n",
        "train_path = 'https://raw.githubusercontent.com/ichekhovskikh/recommendation-system/master/data.json' #@param {type: \"string\"}\n",
        "test_path = 'https://raw.githubusercontent.com/ichekhovskikh/recommendation-system/master/test.json' #@param {type: \"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzY-WMJjJhtR",
        "colab_type": "text"
      },
      "source": [
        "## Опредлим функцию для чтения и предварительной обработки текста\n",
        "Ниже мы определяем функцию для открытия  train/test файла, предварительно обрабатываем каждый текст датасета, используя простой инструмент предварительной обработки gensim (то есть, разбиваем текст на отдельные слова, удалите знаки препинания, установите строчные буквы и т. д.), лемматизацию, удаление стоп слов и возвращаем список слов. Для обучения модели нам нужно будет связать тег с каждым документом учебного корпуса. В нашем случае тег - это идентификатор статьи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFO_znw317kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def lemmatize(words):\n",
        "    for word in words:\n",
        "        yield morph.parse(word)[0].normal_form"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr6Qz8Ucw_ee",
        "colab_type": "text"
      },
      "source": [
        "Удаление стоп слов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRm8tmSe17Hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    return [word for word in words if word not in russian_stopwords]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB82kEYi-nek",
        "colab_type": "text"
      },
      "source": [
        "Предобработка текста статьи:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHwqCiuN-hDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def advanced_preprocess(text):\n",
        "    normalized_text = gensim.utils.simple_preprocess(text)\n",
        "    normalized_text = list(lemmatize(normalized_text))\n",
        "    normalized_text = remove_stopwords(normalized_text)\n",
        "    return normalized_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5agV69PVxEIl",
        "colab_type": "text"
      },
      "source": [
        "Отрытие файла с корпусом статей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMO4zHrqGTws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_corpus(corpus_path):\n",
        "    with urllib.request.urlopen(corpus_path) as corpus_url:\n",
        "        corpus = json.loads(corpus_url.read().decode())\n",
        "        for article in corpus:\n",
        "            sentences = tokenize.sent_tokenize(article['text'], 'russian')\n",
        "            normalized_sentences = []\n",
        "            for sentence in sentences:\n",
        "                normalized_sentences.append(' '.join(advanced_preprocess(sentence)))\n",
        "            yield normalized_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_nR03Khn6Lds"
      },
      "source": [
        "Получение исходного текста статьи по индексу:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1gSBZ1G1BNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_article_text_by_index(index, corpus_path):\n",
        "    with urllib.request.urlopen(corpus_path) as corpus_url:\n",
        "        corpus = json.loads(corpus_url.read().decode())\n",
        "        return corpus[index]['text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui3oWTnrxKNt",
        "colab_type": "text"
      },
      "source": [
        "Загружаем корпуса:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0vJrTipGemC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_corpus = list(read_corpus(train_path))\n",
        "test_corpus = list(read_corpus(test_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKA3sFQxKYJP",
        "colab_type": "text"
      },
      "source": [
        "Давайте посмотрим на учебный и тестовый корпуса:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9aPeDPvGgve",
        "colab_type": "code",
        "outputId": "a9348397-1453-4545-da37-8e3243ee5bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(train_corpus[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['общественный жизнь экономика рынок каждый готовить блин сковорода антипригарный покра тие знать важный температура приготовление который зависеть цвета форма изделие домаш условие некоторый колебание цвет толщина форма вполне приемлемый промышленный произа водство блин сложный процесс неоднородность готовый продукт становиться больший пра пятствие успешный реали зации торговый сеть новое технический решение стабилизация качество промышленный ный производство блин разрабо таль специалист шведский фирма formcook промышленный печь термообработка самый разно образный продукт мясо птица рыба овощ пять год поставлять россия компания агро надёжный высокопроиза водительный оборудование успеть завоевать авторитет российский специалист мясной рыбный молочный промышленность сис тема общепит инженер конструктор фирма formcook промышленный производство блин год спустя запустить эксплуата цию один инновационный система приготовление пищевой промышленность течение десяток год обходиться старомодный циркулярный уста новками приготовление бли новый традиция плохой расположение блин круглый поверхность увеличить вающийся окружность начинать центр возникать проблема площадь центральный часть маленький площадь край существовать подход дать ной проблема один уменьше ние внутренний область ориена тир расчёт количество блин помещаться внешний часть случай необходимый принять риться потеря место произво дительность энергия свобода ном пространство блин рис два подход разместить больший количество блин внеш хле бо дук технический инновация производство блин рис традиционный циркулярный технология приготовление блин часть меньший количество центр такой подход воз никать дополнительный проблема блин циркулярный зона перемещаться двигаться пря молинейно транспортёр один сторона транспортёр блин рис один проблема циркуляр ной технология потребность два устройство приготовля ния блин оба сторона кроме дать технология возможный разный температура один общий нагревательный уста ройство рис инновационный решение новый оборудование серия fbc компания formcook совместить современный конструкция агрег тов подходящий жидкий дукт малый масса отный шение площадь рабочий поверх ность отличие циркулярный установка машина fbc прямоль нейный использоваться антипереть гарный система транспортировка приготовление блин подвод теплота снизу прямолинейный кон струкция исключать проблема свя занный разница окружность позволять встраивать автоматиче ский устройство равномерный пропекание бли новый оба сторона запатентовать вакуумный сис тема обеспечивать постоянный кон такт теплопроводящий поверхность гарантировать равномерный распря деление температура весь сис тема приготовление рис отличие циркуляционный установка одинаковый температ рой весь площадь приготовля ния прямолинейный машина fbc позволять работать различный температура разный зона готовление весь длина пов шение температура начало цессать использоваться быстрый стабилизация жидкий тест дания блин необходимый один кова форма круглый прямо угольный затем происходить сни жение температура исключ ния неравномерный пропекание пригорание повторный повышение температура приготовление переворачивание блин сокращать общий приго товление увеличивать производить тельность особенность конструкция машина fbc приготовля ния блин встроить дозатор тест который оснастить личный насадка насос погра женный ёмкость предварительно замесить жидкий тест блин подавать система дозить рования также перемешивать тесто предотвращать отстаивание сенсорный дисплей обеспечивать лёгкий доступ к весь параметр система управление рецепт общий время приготовление речь лироваться температура выставляться индивидуально каждый зона готовление уста ройство подхватывать ряд блин переворачивать подж ривания один сторона передавать щий конвейер аккуратно перемещать блин ровный ряд облёгкий ния дальнейший обработка охлаж дения упаковка наполнение встроить бесщёточный система мойка машина обеспечивать посто ять чистота лента опыт эксплуатация новое о рудования европа оказаться успеший ным впереди освоение россия ский рынок хле бо дук рынок машина оборудование рис современный прямолинейный технология приготовление блин'], ['удк экономический эффективность производство молоко молочный продукт ооо угмк агро production efficiency of milk and dairy products at ltd ugmc agro порубенко студент уральский агарный университет екатеринбург ул карл либкнехт рецензент самойлов кандидат наука доцент кротов кандидат экономический наука доцент мальков старший преподаватель аннотация экономический эффективность производство молоко молочный продукция предполагать оценка деятельность предприятие угмк агро цепочка производство молоко переработка реализация молочный продукция ключевой слово эффективность себестоимость прибыль рентабельность реализация цена рыночный конъюнктура загруженность мощность эко номический механизм затратный механизм издержка abstract economic efficiency of manufacture of milk and dairy products involves the evaluation of the activity of the enterprises of ltd ugmc agro in the chain of milk production processing and sale of dairy products keywords efficiency cost profit profitability implementation price market conditions competitive ness utilization of production capacities economic mechanism expensive mechanism costs подкомплекс свердловский область являться приоритетный направление развитие сельский хозяйство пищевой промышленность регион насто ящий время молочный промышленность превратиться крупный отрасль пищевой инд стрия который занимать один ведущий место среди отрасль производить предмет требление управлять компания ооо угмк агро создать содействие компания угмк состав управлять компания ооо угмк агро входить крупный предприятие молочный подкомплекс ооо угмк агро задействовать несколько предприятие зао агрофирма патрухо зани маяться производство молоко поставка молочный завод оно реализоваться фирменный сеть входящая состав молочный завод розничный торговля экономический эффективность производство молоко молочный продукция предполагать оценка деятельность предприятие угмк агро цепочка производство молоко перер боткать реализация молочный продукция последний год зао агрофирма патрухо показывать хороший результат дея тельность обеспечить высокий ресурсный потенциал стабильный обеспеченность ресурс позволить хозяйство последний год увести чить стоимость валовый продукция хозяйство фактический цена реализация миллион рубль основное счёт увеличение объём производство продукция жи вотноводство положительный динамик рост объём производство также благоприятный рыночный конъюнктура позволить агрофирма существенно улучшить результат деятельность следний год чистый прибыль агрофирма увеличиться миллион рубль молочный завод эффективность производство всецело зависеть развитие агрофирма патрухо объём переработка сырьё последний год увести чилися однако рост объём переработка ведущий направление позволить уве личить валовый продукция фактический цена реализация миллион рубль мощность молочный завод использоваться менее сравнение прибыль реализация молочный продукция увеличить лася миллион рубль рост прибыть обеспечить инфляционный процесс сколько рентабельность отрасль снизиться оценка эффективность производство молоко агрофирма патрухо показать след ть основной показатель развитие молочный скотоводство период год сви детельствовать хозяйство дать отрасль стабильно развиваться объесть произа водство молоко хозяйство последний год вырасти счёт рост поголовье корова гол гол счёт увеличение продуктивность корова килограмм один корова год наращивание объём валовый производство молоко позволить хозяйство увеличить объесть реализация тысяча уровень товарность отчётный год составить процентный пункт применение интенсивный фактор производство следствие рост продуктивность корова положительно сказываться расход корм затрата труд молоко дать показатель один самый низкий область анализировать период расход корм молоко увеличиться ед затрата труд молый ка вырасти составить отчётный год человекочас сожаление хозяйство смочь противостоять рост себестоимость последний год себестоимость молоко увеличиться рубль стоимость ед производство молоко вырасти рубль основной рост себестоимость молоко связать уве личение расход корма оплата труд отчисление чий расход последний год валовый производство вид корм агрофирма сократиться тысяча основный причина снижение объём корм уменьшение валовый производство зерно вследствие существенный сокращение площадь посев это привести тот выход корм ед га сельхозугодье снизиться га условный голова скот снижение составить ед целое ситуация обеспеченность собственный корма хозяйство оставаться сто бильный устойчивый реализация молоко полный объём осуществляться ооо угмк агро верхнепыш минский молочный завод хозяйство ежедневно отправлять молоко завод высокий сорт остальной первое сорт составлять мощность молочный завод объесть реализация молоко анализировать период увеличиться тысяча счёт рост объём производство уровень товарность отчётный год анализ цена реализация коммерческий себестоимость молоко показывать темп рост цена реализация опережать рост коммерческий себестоимость сочетание рост субсидия молоко прибыль результат дать отрасль улучшиться реали зуть молоко учёт субсидия хозяйство получить прибыль миллион рубль основной проблема агрофирма оставаться низкий цена реализация который ниже среднерыночный обеспечивать некоторый молочный завод очередь показатель молочный завод нестабильный отр жаться результат деятельность затрата молочный продукция увеличить ться вследствие увеличение цена сырьё такой образ прибыль реализация молочный продукт увеличиться рубль улучшение сбыт продукция структура молочный завод включить собственный фирменный торговый сеть также транспортный цех машина фирменный тор говый сеть реализоваться весь производить молочный продукция основной проблема молочный завод являться низкий загруженность мощность такой образ подкомплекс угмк агро выделить сколько основный проблема ухудшать условие участник объединение таковой экономический механизм взаиморасчёт участник приводить низка цена реализация сырьё потеря агрофирма низка цена ежегодно составлять миллион рубль низкий загруженность мощность молочный завод вести рост издержка производство молочный продукция также выявить сумма кредиторский задолженность молочный завод агро фирма составлять ежегодно среднее миллион рубль дальнейший повышение уровень эффективность производство молоко молочный продукт предлагаться следующий мероприятие увеличение загрузка мощность агрофирма счёт увеличение объём производство молоко экономический механизм взаиморасчёт использование тратный механизм ввод норматив затрата прибыль выручка быть общий результ работа объединение быть распределяться соответствие вклад затрата каждый го участник такой образ это привести увеличение прибыть агрофирма патрухо загрузка мощность молочный завод который позволить снизить издержка переработка молоко увеличить прибыльность отрасль миллион рубль работа поставщик молоко предложение высокий цена снижение собственный издержка развитие фирменный торговый сеть список воронин правовой регулирование повышение качество российский продукция аграрный земельный право http elibrary ru item asp id http elibrary ru item asp id http elibrary ru contents asp issueid http elibrary ru contents asp issueid selid кижлай батыршина рогалев методический подход оценка эф фективность производство молоко аграрный вестник урал кижлай экономика организация управление производ ство учебный пособие екатеринбург ургсха курс лекция дисциплина организация планирование производство перераб тывать предприятие сост самойлов екатеринбург ургсха норина методический практический подход оценка эффективность использый вания ресурсный потенциал обоснование механизм обеспечение устойчивость эко номический развитие предприятие екатеринбург ургсха самойлов мальков оценка эффективность производство сбыт продукция животноводство интегрировать формирование аграрный вестник урал']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrWLt9Z8Gm66",
        "colab_type": "code",
        "outputId": "ebb791c6-7df1-4a58-aedd-1caa9d119e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(test_corpus[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['язык ассемблер машинный ориентировать язык низкий уровень', 'команда прямо соответствовать отдельный команда машина также предоставлять дополнительный возможность облегчение такой макрокоманда выражение средство обеспечение модульность программа', 'рассматриваться автокод расширить конструкция язык высокий уровень', 'являться существенно платформо зависимый', 'язык ассемблер различный аппаратный платформа несовместимый хотя мочь целое подобный', 'русский язык именоваться просто ассемблер типичный выражение тип писать программа ассемблер строго говорить неверный ассемблер именоваться утилит трансляция программа язык ассемблер объектный код компьютер'], ['перитонит развиваться вследствие бактериальный инфицирование брюшной полость', 'подавлять большинство пациент перитонит обнаруживать различный сочетание аэробный анаэробный микроорганизм', 'отсутствие рост микрофлора стандартный исследование условие гнойный каловый перитонит свидетельствовать лишь высокий вероятность доминировать анаэробный обсемененность брюшной полость', 'трудно возможно верифицировать']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qagqjk0DSpLa",
        "colab_type": "text"
      },
      "source": [
        "Создайте три пустых файла в Google Drive для сохранения в них словаря, модели Word2Vec, модели Skip Throughts Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8mvv1b-TB5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_dictionary = '/content/drive/My Drive/sample_data/vocab.pkl'\n",
        "path_to_word2vec = '/content/drive/My Drive/sample_data/word2vec.bin'\n",
        "path_to_model = '/content/drive/My Drive/sample_data/model.npz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-cTR8Uz7JYp",
        "colab_type": "text"
      },
      "source": [
        "# Обучение модели\n",
        "## Создание словаря\n",
        "Состовим словарь из тренеровочного корпуса предложений и сохраним его по пути path_to_dictionary для дальнейшего использования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0bGe_WXYTF",
        "colab_type": "text"
      },
      "source": [
        "Объединение всех предложений в один список"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmiteWv3VhOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(text):\n",
        "    return [item for sublist in text for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGBpE5hXXmdP",
        "colab_type": "text"
      },
      "source": [
        "Создание и сохранение словаря"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqyQi72JT0KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentenses = flatten(train_corpus)\n",
        "worddict, wordcount = vocab.build_dictionary(sentenses)\n",
        "vocab.save_dictionary(worddict, wordcount, path_to_dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-zg08E4X5Yc",
        "colab_type": "text"
      },
      "source": [
        " ## Создание модели Word2Vec\n",
        "Составим модель Word2Vec из тренеровочного корпуса предложений и сохраним его по пути path_to_word2vec для дальнейшего использования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7rjlG1VaYGK",
        "colab_type": "text"
      },
      "source": [
        "Разделить предложение на слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG41WYwNY9t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_tokenize(text):\n",
        "    flat_text = flatten(text)\n",
        "    return [item.split(' ') for item in flat_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP8UTYRvafOV",
        "colab_type": "text"
      },
      "source": [
        "Создание и сохранение модели Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6w0x7RlnzVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Укажите параметры обучения модели слов:\n",
        "vector_size = 80 #@param\n",
        "window =  5 #@param\n",
        "epochs =  100 #@param\n",
        "min_count = 2 #@param\n",
        "alpha = 0.001 #@param\n",
        "learning_method = \"skip-gram\" #@param [\"skip-gram\", \"CBOW\"] {type:\"raw\"}\n",
        "\n",
        "sg = 1\n",
        "if (learning_method == \"CBOW\"):\n",
        "    sg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9duhzq_4YU1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = word_tokenize(train_corpus)\n",
        "model = Word2Vec(\n",
        "    words, \n",
        "    size=vector_size, \n",
        "    window=window, \n",
        "    min_count=min_count, \n",
        "    alpha=alpha,\n",
        "    sg=sg,\n",
        "    iter=epochs,\n",
        "    workers=4)\n",
        "\n",
        "model.wv.save_word2vec_format(path_to_word2vec, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sVINChchw9T",
        "colab_type": "text"
      },
      "source": [
        "# Создание модели Skip Throughts Vectors\n",
        "Создадим модель Skip Throughts Vectors для преобрахования текстов в вектора.\n",
        "Сохраним ее в Google Drive по пути path_to_model. Параметры обучения:\n",
        "- dim_word: размерность вектора слов в RNN сети\n",
        "- max_epochs: количество эпох обучения\n",
        "- displayFreq: отображение прогресса после такого количества эпох\n",
        "- learning_rate: коэффициент обучения\n",
        "- n_words: размерность словаря\n",
        "- maxlen_w: максимальное количество слов в предложении, если ниже заданной - игнорировать\n",
        "- saveto: путь для сохранения модели\n",
        "- dictionary: путь к словарю\n",
        "- saveFreq: частота сохранения модели в эпохах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aoKVTgSS2sC1",
        "colab": {}
      },
      "source": [
        "#@title Укажите параметры обучения модели предложений:\n",
        "max_epochs = 100 #@param\n",
        "neurons_count = 2400 #@param\n",
        "learning_rate = 0.01 #@param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KvtLIZOiAxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentenses = flatten(train_corpus)\n",
        "%time train.trainer(\n",
        "    sentenses, \n",
        "    n_words = len(worddict) + 2, # + 2 (EOF, UNK)\n",
        "    dim=neurons_count,\n",
        "    learning_rate=learning_rate,\n",
        "    max_epochs=max_epochs,\n",
        "    dictionary = path_to_dictionary,\n",
        "    saveto = path_to_model,\n",
        "    saveFreq = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTcZvsQQqYTV",
        "colab_type": "text"
      },
      "source": [
        "Загрузка обученной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFvH5FqpqEuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tools.load_model(\n",
        "    path_to_model = path_to_model,\n",
        "    path_to_dictionary = path_to_dictionary,\n",
        "    path_to_word2vec = path_to_word2vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OriWNZ5RiUVd",
        "colab_type": "text"
      },
      "source": [
        "# Поиск похожих текстов на основе обученной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeuA40DoSi0x",
        "colab_type": "text"
      },
      "source": [
        "Обратная сглаженная частота (вес слова), где\n",
        "- a: гиперпараметр, который обычно равен 0.001 (конфигурация, внешняя по отношению к модели, значение которой невозможно оценить по данным):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCA8NOFtSZ0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 0.001\n",
        "\n",
        "def sif(word, sentence):\n",
        "    frequency = sentence.count(word) / len(sentence)\n",
        "    return a / (a + frequency) \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyOLBTMAVVml",
        "colab_type": "text"
      },
      "source": [
        "Получить вектор текста:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp9jnjq1Zahc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def paragraph_vector(model, paragraph):\n",
        "    sentence_vectors = tools.encode(model, paragraph)\n",
        "    paragraph_vector = []\n",
        "    vector_count = 0\n",
        "    for sentence_vector in sentence_vectors:\n",
        "        if not paragraph_vector:\n",
        "            paragraph_vector = sentence_vector\n",
        "        else: \n",
        "            paragraph_vector = [x + y for x, y in zip(paragraph_vector, sentence_vector)]\n",
        "            vector_count += 1\n",
        "    if vector_count != 0:\n",
        "        paragraph_vector = [x / vector_count for x in paragraph_vector]\n",
        "    return paragraph_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r56A1M-4g9y0",
        "colab_type": "text"
      },
      "source": [
        "Определение косинусной близости двух векторов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ8hxIVpStCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(first_vector, second_vector):\n",
        "    numerator = sum([x * y for x, y in zip(first_vector, second_vector)])\n",
        "    first_norm = pow(sum([x * x for x in first_vector]), 0.5)\n",
        "    second_norm = pow(sum([x * x for x in second_vector]), 0.5)\n",
        "    return numerator / (first_norm * second_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jak5jPaK6QmC",
        "colab_type": "text"
      },
      "source": [
        "Поиск похожих текстов из корпуса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omwDc4Vd6YIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sims(model, corpus, corpus_path, paragraph, count = 4):\n",
        "    result = []\n",
        "    compared_vector = paragraph_vector(model, paragraph)\n",
        "    for index, text in enumerate(corpus):\n",
        "        text_vector = paragraph_vector(model, text)\n",
        "        similarity = cosine_similarity(compared_vector, text_vector)\n",
        "        result.append([similarity, get_article_text_by_index(index, corpus_path)])\n",
        "    return reversed(sorted(result,  key=lambda x: x[0]))[:count]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSeGSybK4tpG",
        "colab_type": "text"
      },
      "source": [
        "# Оценочная модель\n",
        "Чтобы оценить нашу новую модель, мы сначала выведем новые векторы для каждого документа тренировочного корпуса, сравним выведенные векторы с тренировочным корпусом.\n",
        "\n",
        "Проверка выведенного вектора по обучающему вектору является своего рода «проверкой работоспособности» в отношении того, ведет ли модель себя адекватно, хотя и не является реальным значением «точности».\n",
        "\n",
        "Можем взглянуть на пример:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KendqFnt496K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_id = random.randint(0, len(train_corpus) - 1)\n",
        "doc = train_corpus[doc_id]\n",
        "sims = sims(model, train_corpus, train_path, doc)\n",
        "print('ТЕКСТ ИСХДНОГО ДОКУМЕНТА ({}): «{}»\\n'.format(doc_id, get_article_text_by_index(doc_id, train_path)))\n",
        "num = 0\n",
        "for similarity, text in sims:\n",
        "    num += 1\n",
        "    print(u'%s) %s: «%s»\\n' % (num, similarity, text))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eq8rXTHOwBQ",
        "colab_type": "text"
      },
      "source": [
        "# Тестирование модели\n",
        "Используя тот же подход, что и выше, мы выведем вектор для случайно выбранного тестового документа и сравним документ с нашей моделью на глаз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y7K6N4jLIXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_id = random.randint(0, len(test_corpus) - 1)\n",
        "doc = test_corpus[doc_id]\n",
        "sims = sims(model, train_corpus, train_path, doc)\n",
        "print('ТЕКСТ ИСХДНОГО ДОКУМЕНТА ({}): «{}»\\n'.format(doc_id, get_article_text_by_index(doc_id, test_path)))\n",
        "num = 0\n",
        "for similarity, text in sims:\n",
        "    num += 1\n",
        "    print(u'%s) %s: «%s»\\n' % (num, similarity, text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91sOWCLiLOxS",
        "colab_type": "text"
      },
      "source": [
        "Тестирование на малых данных для выявления ошибок в ходе написания кода"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIgFPnpL6CBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = [\"первое предложение\", \"второе предложение\", \"третье предложение\", \"что-то еще предложение\"]\n",
        "text_split_on_words = [['первое', 'предложение'], ['второе', 'предложение'], ['третье', 'предложение'], ['что-то', 'еще', 'предложение']]\n",
        "\n",
        "worddict, wordcount = vocab.build_dictionary(text)\n",
        "vocab.save_dictionary(worddict, wordcount, path_to_dictionary)\n",
        "\n",
        "model = Word2Vec(text_split_on_words, size=300, window=5, min_count=1, workers=4)\n",
        "model.wv.save_word2vec_format(path_to_word2vec, binary=True)\n",
        "\n",
        "train.trainer(\n",
        "    text, \n",
        "    n_words=len(worddict) + 2,\n",
        "    dictionary=path_to_dictionary,\n",
        "    saveto=path_to_model,\n",
        "    saveFreq=1)\n",
        "\n",
        "model = tools.load_model(\n",
        "    path_to_model = path_to_model,\n",
        "    path_to_dictionary = path_to_dictionary',\n",
        "    path_to_word2vec = path_to_word2vec)\n",
        "\n",
        "vectors = tools.encode(model, text)\n",
        "print(cosine_similarity(vectors[0], vectors[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BSpkRxWUrC9B"
      },
      "source": [
        "# Поиск похожих научных документов\n",
        "Выполните поиск похожих научных статей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrflInTzrgmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Укажите путь к тексту статьи в формате *.txt или введите текст статьи:\n",
        "article_text = '' #@param {type: \"string\"}\n",
        "article_path = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/PY0101EN/labs/example1.txt' #@param {type: \"string\"}\n",
        "\n",
        "if (article_text == ''):\n",
        "    with urllib.request.urlopen(article_path) as article_url:\n",
        "      article_text = article_url.read()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6JqjIFpu46v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_text = advanced_preprocess(article_text)\n",
        "sims = sims(model, train_corpus, train_path, normalized_text)\n",
        "\n",
        "print('ТЕКСТ ИСХДНОГО ДОКУМЕНТА «{}»\\n'.format(article_text)\n",
        "num = 0\n",
        "for similarity, text in sims:\n",
        "    num += 1\n",
        "    print(u'%s) %s: «%s»\\n' % (num, similarity, text))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}